# ğŸ§ª UIL Mock Mode Guide

## Overview

Mock Mode allows you to test UIL functionality **without running AI Provider Bridge**. Perfect for:
- âœ… Development and testing
- âœ… Integration testing without API costs
- âœ… UI/UX development
- âœ… Debugging UIL logic

---

## ğŸš€ Quick Start

### Enable Mock Mode

```bash
# In terminal
export UIL_MOCK_MODE=true

# Or in .env
UIL_MOCK_MODE=true
```

### Restart Application

```bash
npm run dev
```

---

## ğŸ§ª Testing

### Option 1: Run Test Script

```bash
./test-uil-mock.sh
```

This will test all 7 endpoints:
1. Health Check
2. Analyze (ØªØ­Ù„ÙŠÙ„)
3. Chat (Ù…Ø­Ø§Ø¯Ø«Ø©)
4. Summarize (ØªÙ„Ø®ÙŠØµ)
5. Plan (ØªØ®Ø·ÙŠØ·)
6. Code (Ø¨Ø±Ù…Ø¬Ø©)
7. Statistics

### Option 2: Manual Testing

```bash
# Health Check
curl http://localhost:5000/api/uil/health

# Chat Test
curl -X POST http://localhost:5000/api/uil/chat \
  -H 'Content-Type: application/json' \
  -d '{"prompt":"Ù…Ø±Ø­Ø¨Ø§Ù‹!","meta":{"module":"support"}}'

# Analysis Test
curl -X POST http://localhost:5000/api/uil/analyze \
  -H 'Content-Type: application/json' \
  -d '{"prompt":"Analyze sales data","meta":{"module":"accounting"}}'
```

### Option 3: TypeScript Testing

```typescript
// Set environment variable first
process.env.UIL_MOCK_MODE = "true";

import { UIL_chat, UIL_analyze } from './nucleus/uil/UIL';

// Test chat
const chatResult = await UIL_chat("Hello!");
console.log(chatResult);

// Test analysis
const analysisResult = await UIL_analyze("Analyze Q3 data");
console.log(analysisResult);
```

---

## ğŸ“Š Mock Responses

### Analysis (ØªØ­Ù„ÙŠÙ„)
```
ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©:

**Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**
1. Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠ: Ø§Ø±ØªÙØ§Ø¹ Ø¨Ù†Ø³Ø¨Ø© 15% ÙÙŠ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª
2. ØªØ­Ø³Ù† Ø§Ù„Ø±Ø¨Ø­ÙŠØ©: Ø§Ø±ØªÙØ§Ø¹ 18% ÙÙŠ ØµØ§ÙÙŠ Ø§Ù„Ø±Ø¨Ø­
3. ØªÙˆØµÙŠØ©: Ù…Ø±Ø§Ù‚Ø¨Ø© Ù†Ù…Ùˆ Ø§Ù„Ù…ØµØ§Ø±ÙŠÙ Ø§Ù„ØªØ´ØºÙŠÙ„ÙŠØ©

**Ø§Ù„ØªÙˆØµÙŠØ§Øª:**
- Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø²Ø®Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ
- ØªØ­Ø³ÙŠÙ† ÙƒÙØ§Ø¡Ø© Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ
- ØªÙˆØ³ÙŠØ¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª
```

### Conversation (Ù…Ø­Ø§Ø¯Ø«Ø©)
```
Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ! ğŸ‘‹

ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ. ÙØ§ØªÙˆØ±ØªÙƒ Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù‚Ø¯ ØªÙƒÙˆÙ† Ø£Ø¹Ù„Ù‰ Ù„Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ØªØ§Ù„ÙŠØ©:
1. Ø®Ø¯Ù…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§
2. ØªØ¬Ø¯ÙŠØ¯ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ Ø§Ù„Ø³Ù†ÙˆÙŠ
3. Ø±Ø³ÙˆÙ… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©

Ù‡Ù„ ØªØ±ÙŠØ¯ Ù…Ø±Ø§Ø¬Ø¹Ø© ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ø¹Ø§Ù‹ØŸ
```

### Code (Ø¨Ø±Ù…Ø¬Ø©)
```typescript
function validateEmail(email: string): boolean {
  try {
    const emailRegex = /^[a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$/;
    
    if (!emailRegex.test(email)) {
      return false;
    }
    
    if (email.length > 254) {
      return false;
    }
    
    return true;
  } catch (error) {
    console.error('Email validation error:', error);
    return false;
  }
}
```

---

## ğŸ”„ Provider Distribution

Mock Mode simulates adaptive routing:

| Task Type | Mock Provider | Latency |
|-----------|---------------|---------|
| analysis | llama | 500-2000ms |
| conversation | mistral | 500-2000ms |
| summarization | openai | 500-2000ms |
| planning | claude | 500-2000ms |
| coding | openai | 500-2000ms |

---

## ğŸ“ˆ Mock Statistics

```json
{
  "mode": "mock",
  "requests_total": 127,
  "success_rate": 100.0,
  "avg_latency_ms": 1234,
  "provider_stats": {
    "openai": { "requests": 45, "success": 45, "avg_latency": 1100 },
    "llama": { "requests": 35, "success": 35, "avg_latency": 1500 },
    "mistral": { "requests": 30, "success": 30, "avg_latency": 1200 },
    "claude": { "requests": 17, "success": 17, "avg_latency": 1000 }
  }
}
```

---

## ğŸ¥ Mock Health

```json
{
  "healthy": true,
  "bridge": {
    "status": "ok",
    "mode": "mock",
    "providers": {
      "openai": { "available": true },
      "llama": { "available": true },
      "mistral": { "available": true },
      "claude": { "available": true }
    }
  }
}
```

---

## ğŸ”§ Customizing Mock Responses

Edit `nucleus/uil/UIL-Mock.ts` to customize responses:

```typescript
const MOCK_RESPONSES: Record<string, string> = {
  analysis: "Your custom analysis response...",
  conversation: "Your custom conversation response...",
  // ... etc
};
```

---

## âš ï¸ Limitations

Mock Mode simulates UIL behavior but:
- âŒ No actual AI inference
- âŒ No real provider selection logic
- âŒ Fixed latency simulation
- âŒ No caching behavior
- âŒ No real error scenarios

**Use Mock Mode for:**
- âœ… UI/UX development
- âœ… Integration testing
- âœ… API contract validation
- âœ… Performance testing (structure)

**Use Real Bridge for:**
- âœ… Production deployment
- âœ… AI quality testing
- âœ… Provider performance comparison
- âœ… Real-world scenarios

---

## ğŸ”„ Switching Between Modes

### To Mock Mode
```bash
export UIL_MOCK_MODE=true
npm run dev
```

### To Real Bridge
```bash
unset UIL_MOCK_MODE
# Start Bridge first
cd ai-bridge
python3 bridge_enhanced.py --mode adaptive --port 7010 &
cd ..
npm run dev
```

---

## ğŸ“ Integration Test with Mock

```bash
# Enable mock mode
export UIL_MOCK_MODE=true

# Run integration tests
npx tsx nucleus/uil/integration-tests.ts
```

Expected output:
```
âœ… Passed: 10/10
ğŸ“Š Avg Response Time: ~1000ms
ğŸ“¡ Provider Distribution: All simulated
```

---

**Surooh Empire - UIL Mock Mode**  
**Perfect for Development & Testing**
